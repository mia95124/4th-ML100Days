import numpy as np
import csv
import math
import pandas as pd
import os
os.getcwd()
import random

seed = 9487
np.random.seed(seed)

def valid(x, y):
  # TODO: Try to filter out extreme values.
  #  ex: If PM2.5 > 100, then we don't use the data to train (return False), otherwise return True,
  data_t = np.transpose(data)
  #print(y)

  """feats_num = len(feats)
  for i in range(feats_num):
    for j in range(x.shape[0]):
      n = 1.5 #幾倍的outliner
      x_Q3 = np.percentile(data_t[feats[i], ], 75)
      x_Q1 = np.percentile(data_t[feats[i], ], 25)

      x_IQR = x_Q3 - x_Q1

      if (x[i, j] > x_Q3+n*x_IQR) or (x[i, j] < x_Q1 - n*x_IQR):
        return False"""
  return True


# Create your dataset
def parse2train(data, feats):

  x = []
  y = []

  # Use data #0~#7 to predict #8 => Total data length should be decresased by 8.
  total_length = data.shape[1] - 8

  for i in range(total_length):
    x_tmp = data[feats, i:i+8] # Use data #0~#7 to predict #8, data #1~#8 to predict #9, etc.
    y_tmp = data[-1, i+8] # last column of (i+8)th row: PM2.5

    # Filter out extreme values to train.
    if valid(x_tmp, y_tmp):
      x.append(x_tmp.reshape(-1,))
      y.append(y_tmp)
  
  # x.shape: (n, 15, 8)
  # y.shape: (n, 1) 
  x = np.array(x)
  y = np.array(y)

  return x,y

# TODO: Implement 2-nd polynomial regression version for the report.
def minibatch(x, y, config):
  
    # Randomize the data in minibatch
    index = np.arange(x.shape[0])
    np.random.shuffle(index)
    x1 = x[index]
    x2 = x1*x1

    x = np.concatenate([x1, x2], axis = 1)
    y = y[index]
    
    # Initialization
    batch_size = config.batch_size
    lr = config.lr
    lam = config.lam
    epoch = config.epoch

    beta_1 = np.full(x[0].shape, 0.9).reshape(-1, 1)
    beta_2 = np.full(x[0].shape, 0.99).reshape(-1, 1)
    # Linear regression: only contains two parameters (w, b).
    w = np.full(x[0].shape, 0.1).reshape(-1, 1)
    bias = 0.1
    m_t = np.full(x[0].shape, 0).reshape(-1, 1)
    v_t = np.full(x[0].shape, 0).reshape(-1, 1)
    m_t_b = 0.0
    v_t_b = 0.0
    t = 0
    epsilon = 1e-8
    
    # Training loop
    for num in range(epoch):
        for b in range(int(x.shape[0]/batch_size)):
            t+=1
            x_batch = x[b*batch_size:(b+1)*batch_size]
            y_batch = y[b*batch_size:(b+1)*batch_size].reshape(-1,1)

            # Prediction of linear regression 
            pred = np.dot(x_batch,w) + bias
            # loss
            loss = y_batch - pred
            
            # Compute gradient
            ## Edit: remove 2 * lam * np.sum(w)  (2022.10.11)
            # https://math.stackexchange.com/questions/1962877/compute-the-gradient-of-mean-square-error
            g_t = np.dot(x_batch.transpose(),loss) * (-2)
            g_t_b = loss.sum(axis=0) * (-2)
            m_t = beta_1*m_t + (1-beta_1)*g_t 
            v_t = beta_2*v_t + (1-beta_2)*np.multiply(g_t, g_t)
            m_cap = m_t/(1-(beta_1**t))
            v_cap = v_t/(1-(beta_2**t))
            m_t_b = 0.9*m_t_b + (1-0.9)*g_t_b
            v_t_b = 0.99*v_t_b + (1-0.99)*(g_t_b*g_t_b) 
            m_cap_b = m_t_b/(1-(0.9**t))
            v_cap_b = v_t_b/(1-(0.99**t))
            w_0 = np.copy(w)
            
            # Update weight & bias
            w -= ((lr*m_cap)/(np.sqrt(v_cap)+epsilon)).reshape(-1, 1)
            bias -= (lr*m_cap_b)/(math.sqrt(v_cap_b)+epsilon)
            

    return w, bias

from argparse import Namespace

# TODO: Tune the config to boost your performance. 
train_config = Namespace(
    batch_size = 100,
    lr = 1e-1,
    lam = 0.001,
    epoch = 1000,
)
data = pd.read_csv("train.csv")
feats = [10]
# 記得改檔名！！！
# Training data preprocessing.

data = data.values
train_data = np.transpose(np.array(np.float64(data)))
train_x, train_y = parse2train(train_data, feats)

# Train your regression model

w, bias = minibatch(train_x, train_y, train_config)

def parse2test(data, feats):
  x = []
  for i in range(90):
    x_tmp = data[feats,8*i: 8*i+8]
    x.append(x_tmp.reshape(-1,))

  # x.shape: (n, 15, 8)
  x = np.array(x)
  return x

data = pd.read_csv('test.csv')
data = data.values

test_data = np.transpose(np.array(np.float64(data)))
test_x1 = parse2test(test_data, feats)
test_x2 = test_x1*test_x1
test_x = np.concatenate([test_x1, test_x2], axis = 1)



with open('my_sol_2.csv', 'w', newline='') as csvf:
    # 建立 CSV 檔寫入器
    writer = csv.writer(csvf)
    writer.writerow(['Id','Predicted'])

    print(test_x.shape) 
    for i in range(int(test_x.shape[0])):
      # Prediction of linear regression 
      prediction = (np.dot(np.reshape(w,-1),test_x[i]) + bias)[0]
      writer.writerow([i, prediction] )

